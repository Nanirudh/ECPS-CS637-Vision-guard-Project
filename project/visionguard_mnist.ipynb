{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c505bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.6.0\n",
      "Cleverhans Version: 4.0.0-edc15c6ec93c96562523dc42ae33c9e7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from tqdm import tqdm\n",
    "import cleverhans\n",
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Tensorflow Version: \" + tf.__version__)\n",
    "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
    "import os\n",
    "# from cleverhans.utils import other_classes\n",
    "# from cleverhans.utils_tf import batch_eval, model_argmax\n",
    "# from cleverhans.attacks import SaliencyMapMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d31f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset='mnist'):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert dataset in ['mnist', 'cifar'], \\\n",
    "        \"dataset parameter must be either 'mnist' 'cifar'\"\n",
    "    if dataset == 'mnist':\n",
    "        # the data, shuffled and split between train and test sets\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        # reshape to (n_samples, 28, 28, 1)\n",
    "        X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "        X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "    elif dataset == 'cifar':\n",
    "        # the data, shuffled and split between train and test sets\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "   \n",
    "    # cast pixels to floats, normalize to [0, 1] range\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    # one-hot-encode the labels\n",
    "    Y_train = np_utils.to_categorical(y_train, 10)\n",
    "    Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y_test.shape)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "def get_model(dataset='mnist'):\n",
    "    \"\"\"\n",
    "    Takes in a parameter indicating which model type to use ('mnist',\n",
    "    'cifar' or 'svhn') and returns the appropriate Keras model.\n",
    "    :param dataset: A string indicating which dataset we are building\n",
    "                    a model for.\n",
    "    :return: The model; a Keras 'Sequential' instance.\n",
    "    \"\"\"\n",
    "    assert dataset in ['mnist', 'cifar'], \\\n",
    "        \"dataset parameter must be either 'mnist' 'cifar'\"\n",
    "    if dataset == 'mnist':\n",
    "        # MNIST model\n",
    "        layers = [\n",
    "            Conv2D(64, (3, 3), padding='valid', input_shape=(28, 28, 1)),\n",
    "            Activation('relu'),\n",
    "            Conv2D(64, (3, 3)),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Dropout(0.5),\n",
    "            Flatten(),\n",
    "            Dense(128),\n",
    "            Activation('relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(10),\n",
    "            Activation('softmax')\n",
    "        ]\n",
    "    elif dataset == 'cifar':\n",
    "        # CIFAR-10 model\n",
    "        layers = [\n",
    "            Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)),\n",
    "            Activation('relu'),\n",
    "            Conv2D(32, (3, 3), padding='same'),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(64, (3, 3), padding='same'),\n",
    "            Activation('relu'),\n",
    "            Conv2D(64, (3, 3), padding='same'),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(128, (3, 3), padding='same'),\n",
    "            Activation('relu'),\n",
    "            Conv2D(128, (3, 3), padding='same'),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Flatten(),\n",
    "            Dropout(0.5),\n",
    "            Dense(1024, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "            Activation('relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(512, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "            Activation('relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(10),\n",
    "            Activation('softmax')\n",
    "        ]\n",
    "\n",
    "    model = Sequential()\n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c6862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset, epoch=1, batch_size=256):\n",
    "    assert dataset in ['mnist', 'cifar'], \\\n",
    "        \"dataset parameter must be either 'mnist', 'cifar'\"\n",
    "    print('Data set: %s' % dataset)\n",
    "    X_train, Y_train, X_test, Y_test = get_data(dataset)\n",
    "    model = get_model(dataset)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adadelta',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, Y_train,\n",
    "        epochs=epoch,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, Y_test)\n",
    "    )\n",
    "    model.save('model_%s.h5' % dataset) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23b97131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: mnist\n",
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 155s 648ms/step - loss: 2.3008 - accuracy: 0.1118 - val_loss: 2.2794 - val_accuracy: 0.2125\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 152s 647ms/step - loss: 2.2775 - accuracy: 0.1501 - val_loss: 2.2514 - val_accuracy: 0.2849\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 151s 644ms/step - loss: 2.2519 - accuracy: 0.1956 - val_loss: 2.2206 - val_accuracy: 0.3341\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 152s 647ms/step - loss: 2.2239 - accuracy: 0.2334 - val_loss: 2.1848 - val_accuracy: 0.3981\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 152s 645ms/step - loss: 2.1902 - accuracy: 0.2737 - val_loss: 2.1413 - val_accuracy: 0.4758\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 152s 648ms/step - loss: 2.1505 - accuracy: 0.3113 - val_loss: 2.0876 - val_accuracy: 0.5506\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 152s 645ms/step - loss: 2.0990 - accuracy: 0.3539 - val_loss: 2.0207 - val_accuracy: 0.6204\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 152s 646ms/step - loss: 2.0392 - accuracy: 0.3924 - val_loss: 1.9379 - val_accuracy: 0.6814\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 152s 646ms/step - loss: 1.9650 - accuracy: 0.4283 - val_loss: 1.8383 - val_accuracy: 0.7200\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 151s 643ms/step - loss: 1.8768 - accuracy: 0.4653 - val_loss: 1.7220 - val_accuracy: 0.7493\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 152s 645ms/step - loss: 1.7818 - accuracy: 0.4962 - val_loss: 1.5938 - val_accuracy: 0.7750\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 152s 647ms/step - loss: 1.6784 - accuracy: 0.5263 - val_loss: 1.4599 - val_accuracy: 0.7918\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 152s 646ms/step - loss: 1.5723 - accuracy: 0.5534 - val_loss: 1.3270 - val_accuracy: 0.8028\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 152s 645ms/step - loss: 1.4791 - accuracy: 0.5715 - val_loss: 1.2051 - val_accuracy: 0.8132\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 151s 644ms/step - loss: 1.3852 - accuracy: 0.5936 - val_loss: 1.0960 - val_accuracy: 0.8204\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 152s 646ms/step - loss: 1.3100 - accuracy: 0.6100 - val_loss: 1.0029 - val_accuracy: 0.8261\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 152s 647ms/step - loss: 1.2385 - accuracy: 0.6264 - val_loss: 0.9237 - val_accuracy: 0.8315\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 152s 645ms/step - loss: 1.1789 - accuracy: 0.6400 - val_loss: 0.8576 - val_accuracy: 0.8359\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 151s 644ms/step - loss: 1.1292 - accuracy: 0.6518 - val_loss: 0.8024 - val_accuracy: 0.8391\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 152s 645ms/step - loss: 1.0856 - accuracy: 0.6647 - val_loss: 0.7560 - val_accuracy: 0.8423\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 151s 644ms/step - loss: 1.0448 - accuracy: 0.6744 - val_loss: 0.7157 - val_accuracy: 0.8472\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 151s 644ms/step - loss: 1.0121 - accuracy: 0.6826 - val_loss: 0.6817 - val_accuracy: 0.8503\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 151s 644ms/step - loss: 0.9784 - accuracy: 0.6916 - val_loss: 0.6521 - val_accuracy: 0.8531\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 152s 645ms/step - loss: 0.9576 - accuracy: 0.6987 - val_loss: 0.6276 - val_accuracy: 0.8543\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 156s 663ms/step - loss: 0.9247 - accuracy: 0.7069 - val_loss: 0.6047 - val_accuracy: 0.8573\n"
     ]
    }
   ],
   "source": [
    "train_model(dataset='mnist', epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46cb3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_PARAMS = {\n",
    "    'mnist': {'eps': 0.050, 'eps_iter': 0.010},\n",
    "    'cifar': {'eps': 0.050, 'eps_iter': 0.005}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def craft_one_type(model, X, Y, dataset, attack, batch_size):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    :param sess:\n",
    "    :param model:\n",
    "    :param X:\n",
    "    :param Y:\n",
    "    :param dataset:\n",
    "    :param attack:\n",
    "    :param batch_size:\n",
    "    :return X_adv:\n",
    "    \"\"\"\n",
    "    logits_model = tf.keras.Model(model.input,model.layers[-1].output)\n",
    "    X_adv = []\n",
    "    if attack == 'fgsm':\n",
    "    # FGSM attack\n",
    "        print('Crafting fgsm adversarial samples...')\n",
    "        for train_data in X:\n",
    "            original_image = train_data\n",
    "            original_image = tf.convert_to_tensor(original_image.reshape((1,28,28)))\n",
    "            adv_example_untargeted_data = fast_gradient_method(logits_model, original_image, ATTACK_PARAMS[dataset]['eps'], np.inf, targeted=False)\n",
    "            adv_example_untargeted_data = adv_example_untargeted_data.numpy()\n",
    "            adv_example_untargeted_data = adv_example_untargeted_data.reshape((28,28,1))\n",
    "            X_adv.append(adv_example_untargeted_data)\n",
    "        X_adv = np.array(X_adv)\n",
    "        print('shape  of X_adv is ',X_adv.shape)\n",
    "#     elif attack == 'jsma':\n",
    "#         # JSMA attack\n",
    "#         print('Crafting jsma adversarial samples. This may take a while...')\n",
    "#         X_adv = saliency_map_method(\n",
    "#             sess, model, X, Y, theta=1, gamma=0.1, clip_min=0., clip_max=1.\n",
    "#         )\n",
    "#     else:\n",
    "#         # TODO: CW attack\n",
    "#         raise NotImplementedError('CW attack not yet implemented.')\n",
    "    _, acc = model.evaluate(X_adv, Y, batch_size=batch_size,\n",
    "                            verbose=0)\n",
    "    print(\"Model accuracy on the adversarial test set: %0.2f%%\" % (100 * acc))\n",
    "    np.save('Adv_%s_%s.npy' % (dataset, attack), X_adv)\n",
    "    return X_adv\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def craft_adv_samples(dataset, attack, batch_size=256):    \n",
    "    assert dataset in ['mnist', 'cifar'], \\\n",
    "        \"Dataset parameter must be either 'mnist', 'cifar'\"\n",
    "    assert attack in ['fgsm', 'jsma', 'cw', 'all'], \\\n",
    "        \"Attack parameter must be either 'fgsm'\" \\\n",
    "        \"'jsma' or 'cw' or 'all'\"\n",
    "    assert os.path.isfile('model_%s.h5' % dataset), \\\n",
    "        'model file not found... must first train model using train_model.py.'\n",
    "    model = load_model('model_%s.h5' % dataset)\n",
    "    _, _, X_test, Y_test = get_data(dataset)\n",
    "    _, acc = model.evaluate(X_test, Y_test, batch_size=batch_size,\n",
    "                            verbose=0)\n",
    "    print('Test accuracy is ',acc)\n",
    "    print('Dataset: %s. Attack: %s' % (dataset, attack))\n",
    "    \n",
    "    if(attack == 'all'):\n",
    "        print('Crafting all attacks')\n",
    "        X_adv = np.array()\n",
    "        for attack in ['fgsm','jsma', 'cw']:\n",
    "            attack_adv = craft_one_type(model, X_test, Y_test, dataset, attack,\n",
    "                           batch_size)\n",
    "            X_adv = np.append(X_adv,attack_adv,axis=0)\n",
    "        return (X_adv, model)\n",
    "    else: \n",
    "        print('Crafting attack %s on dataset %s '%(attack, dataset))\n",
    "        return (craft_one_type(model, X_test, Y_test, dataset, attack,\n",
    "                           batch_size), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddec2281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(prob_a, prob_b):\n",
    "    term1 = prob_a*np.log(prob_a)\n",
    "    term2 = prob_a*np.log(prob_b)\n",
    "    term1 = np.sum(term1, axis=1)\n",
    "    term2 = np.sum(term2, axis=1)\n",
    "    #print(term1.shape, term2.shape)\n",
    "    return (term1-term2)\n",
    "\n",
    "def jpeg_compress(x, quality=75):\n",
    "    return tf.image.decode_jpeg(\n",
    "        tf.image.encode_jpeg(\n",
    "            x, format='grayscale', quality=quality),\n",
    "        channels=1)\n",
    "\n",
    "def transform_image(X_adv):\n",
    "    \"\"\"\n",
    "    :param X_adv: adversial input array \n",
    "    :return X_adv_transform: adversial transformed array\n",
    "    \"\"\"\n",
    "    X_adv_transform = []\n",
    "    \n",
    "    for adv_image in X_adv:\n",
    "        adv_image_transform = jpeg_compress(adv_image, quality=92)\n",
    "        X_adv_transform.append(adv_image_transform)\n",
    "    X_adv_transform = np.array(X_adv_transform)\n",
    "    \n",
    "    return X_adv_transform\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def vision_guard(X_test, X_adv, model, threshold, y_test):\n",
    "    \"\"\"\n",
    "    :param X_test:\n",
    "    :param X_adv:\n",
    "    :param model:\n",
    "    :param threshold:\n",
    "    :param dataset:\n",
    "    :param y_test\n",
    "    :return accuracy:\n",
    "    \"\"\"\n",
    "    \n",
    "    _, acc = model.evaluate(X_adv, y_test, batch_size=256,\n",
    "                            verbose=0)\n",
    "    print(\"Accuracy of adversial input without transformation: \",acc)\n",
    "    \n",
    "        \n",
    "    X_adv_transform = transform_image(X_adv)\n",
    "    X_transform     = transform_image(X_test)\n",
    "    prob_a          = model.predict(X_test)\n",
    "    \n",
    "    prob_b_adv  = model.predict(X_adv_transform)\n",
    "    prob_b      = model.predict(X_adv)\n",
    "    \n",
    "    kl_div_adv = np.minimum(KL(prob_a, prob_b_adv),KL(prob_b_adv, prob_a))\n",
    "    kl_div = np.minimum(KL(prob_a, prob_b),KL(prob_b, prob_a))\n",
    "    \n",
    "    \n",
    "  \n",
    "    plt.plot(kl_div,     color='g')\n",
    "    plt.plot(kl_div_adv, color='r')\n",
    "    plt.show()\n",
    "    \n",
    "    print(np.min(kl_div), np.max(kl_div))\n",
    "    print(np.min(kl_div_adv), np.max(kl_div_adv))\n",
    "    \n",
    "    \n",
    "    _, acc = model.evaluate(X_adv_transform, y_test, batch_size=256,\n",
    "                            verbose=0)\n",
    "    print(\"Accuracy of adversial input with transformation: \",acc)\n",
    "    \n",
    "    _, acc = model.evaluate(X_transform, y_test, batch_size=256,\n",
    "                            verbose=0)\n",
    "    print(\"Accuracy of non-adversial input with transformation: \",acc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a8c4715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n",
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n",
      "Test accuracy is  0.8572999835014343\n",
      "Dataset: mnist. Attack: fgsm\n",
      "Crafting attack fgsm on dataset mnist \n",
      "Crafting fgsm adversarial samples...\n",
      "shape  of X_adv is  (10000, 28, 28, 1)\n",
      "Model accuracy on the adversarial test set: 77.95%\n"
     ]
    }
   ],
   "source": [
    "_,_,X_test,y_test = get_data('mnist')\n",
    "X_adv, model = craft_adv_samples('mnist', 'fgsm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0835acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of adversial input without transformation:  0.7795000076293945\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013508815 0.25125766\n",
      "0.07473159 3.0733552\n",
      "Accuracy of adversial input with transformation:  0.11590000241994858\n",
      "Accuracy of non-adversial input with transformation:  0.13079999387264252\n"
     ]
    }
   ],
   "source": [
    "vision_guard(X_test, X_adv, model,0.5, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba138df5",
   "metadata": {},
   "source": [
    "Green color is KL div value for clean images and red color is KL div value on fgsm adversarial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4cf3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
